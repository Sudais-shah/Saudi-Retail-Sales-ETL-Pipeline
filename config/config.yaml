# The below data is for Notebooks testing purposes
# data:
#   raw_dir: ../data/raw/saudi_store_sales_dataset.csv
#   processed_dir: ../data/processed   

# The below data is for main.py so that it can be run from the command line
data:
  raw_dir: data/raw/saudi_store_sales_dataset.csv
  processed_dir: data/processed


spark:
  master: "local[*]"
  app_name: "Retail ETL Pipeline"
  configs:
    spark.sql.shuffle.partitions: 200



general:
  log_level: "INFO"
  feature_flags:
    use_new_preprocessor: false
